# -*- coding: utf-8 -*-
"""CodSoft Telegrambot

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SCCXsQSlthi8JO89AP8_3ay4uM9xLKBJ
"""

!pip install pyTelegramBotAPI
!pip install google-generativeai
TelegramBOT_TOKEN = '7464912389:AAEc0y1EBXuJUbIWieizCAAMnAiaVC4LAVY'

import telebot
import os
import os

import google.generativeai as genai

genai.configure(api_key="AIzaSyBHb0TEo7WGUiTin6XqpL7lwU51tgaRZbs")

# Create the model
# See https://ai.google.dev/api/python/google/generativeai/GenerativeModel
generation_config = {
  "temperature": 1,
  "top_p": 0.95,
  "top_k": 64,
  "max_output_tokens": 8192,
  "response_mime_type": "text/plain",
}

model = genai.GenerativeModel(
  model_name="gemini-1.5-flash",
  generation_config=generation_config,
  # safety_settings = Adjust safety settings
  # See https://ai.google.dev/gemini-api/docs/safety-settings
)

chat_session = model.start_chat(
  history=[
  ]
)




bot = telebot.TeleBot(TelegramBOT_TOKEN)

@bot.message_handler(commands=['start', 'help'])
def send_welcome(message):
    bot.reply_to(message, "Welcome! The MOST POWERFUL AI BOT from IndianServers")

@bot.message_handler(func=lambda message: True)
def handle_message(message):
 try :
  print(message)
  response=chat_session.send_message(message.text)
  bot.reply_to(message, response.text)
 except Exception as e:
        print(f"An error occurred: {e}")
        bot.reply_to(message, "Sorry, I couldn't process your request.")

bot.polling()